#!/usr/bin/env python3
"""
æµ‹è¯•JSONä¿®å¤åŠŸèƒ½
éªŒè¯JSONæ–‡ä»¶çš„å®Œæ•´æ€§å’Œå¯è¯»æ€§
"""

import sys
import os
import json
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from video_segmentation import process_video_segmentation
from utils.json_utils import safe_json_dump, safe_json_dumps, sanitize_for_json
from loguru import logger


def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logger.remove()
    logger.add(
        sys.stderr,
        level="INFO",
        format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{message}</cyan>"
    )


def test_json_serialization():
    """æµ‹è¯•JSONåºåˆ—åŒ–åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•JSONåºåˆ—åŒ–åŠŸèƒ½")
    
    # æµ‹è¯•æ•°æ®åŒ…å«å„ç§å¯èƒ½çš„ç±»å‹
    import numpy as np
    
    test_data = {
        "string": "æµ‹è¯•å­—ç¬¦ä¸²",
        "integer": 42,
        "float": 3.14159,
        "boolean": True,
        "none": None,
        "list": [1, 2, 3],
        "numpy_int": np.int32(123),
        "numpy_float": np.float32(456.789),
        "numpy_array": np.array([1, 2, 3, 4, 5]),
        "numpy_bool": np.bool_(True),
        "nested": {
            "inner_numpy": np.float64(999.999),
            "inner_list": [np.int64(111), np.float32(222.333)]
        }
    }
    
    # æµ‹è¯•æ¸…ç†å‡½æ•°
    logger.info("æµ‹è¯•æ•°æ®æ¸…ç†...")
    cleaned_data = sanitize_for_json(test_data)
    
    # æµ‹è¯•JSONå­—ç¬¦ä¸²è½¬æ¢
    logger.info("æµ‹è¯•JSONå­—ç¬¦ä¸²è½¬æ¢...")
    json_str = safe_json_dumps(cleaned_data)
    
    # éªŒè¯å¯ä»¥é‡æ–°è§£æ
    try:
        parsed_data = json.loads(json_str)
        logger.info("âœ… JSONå­—ç¬¦ä¸²è½¬æ¢å’Œè§£ææˆåŠŸ")
        
        # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
        logger.info(f"åŸå§‹numpy_intç±»å‹: {type(test_data['numpy_int'])}")
        logger.info(f"æ¸…ç†åç±»å‹: {type(cleaned_data['numpy_int'])}")
        logger.info(f"è§£æåå€¼: {parsed_data['numpy_int']}")
        
    except Exception as e:
        logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æ–‡ä»¶å¯¼å‡º
    test_file = "test_json_output.json"
    logger.info(f"æµ‹è¯•æ–‡ä»¶å¯¼å‡º: {test_file}")
    
    if safe_json_dump(cleaned_data, test_file):
        logger.info("âœ… JSONæ–‡ä»¶å¯¼å‡ºæˆåŠŸ")
        
        # éªŒè¯æ–‡ä»¶å†…å®¹
        try:
            with open(test_file, 'r', encoding='utf-8') as f:
                file_data = json.load(f)
            logger.info("âœ… JSONæ–‡ä»¶è¯»å–æˆåŠŸ")
            
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            os.remove(test_file)
            
        except Exception as e:
            logger.error(f"âŒ JSONæ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            return False
    else:
        logger.error("âŒ JSONæ–‡ä»¶å¯¼å‡ºå¤±è´¥")
        return False
    
    return True


def test_video_processing_json():
    """æµ‹è¯•è§†é¢‘å¤„ç†åçš„JSONè¾“å‡º"""
    logger.info("ğŸ¬ æµ‹è¯•è§†é¢‘å¤„ç†JSONè¾“å‡º")
    
    video_path = "test_video.mp4"
    output_dir = "json_test_output"
    
    if not os.path.exists(video_path):
        logger.error(f"æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨: {video_path}")
        return False
    
    # æ‰§è¡Œè§†é¢‘å¤„ç†
    logger.info("æ‰§è¡Œè§†é¢‘å¤„ç†...")
    success = process_video_segmentation(
        video_path,
        output_dir,
        "duration",
        "medium"
    )
    
    if not success:
        logger.error("è§†é¢‘å¤„ç†å¤±è´¥")
        return False
    
    # æ£€æŸ¥ç”Ÿæˆçš„JSONæ–‡ä»¶
    output_path = Path(output_dir)
    json_files = [
        "detection_results.json",
        "quality_metrics.json"
    ]
    
    all_valid = True
    
    for json_file in json_files:
        file_path = output_path / json_file
        
        if not file_path.exists():
            logger.error(f"âŒ JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
            all_valid = False
            continue
        
        logger.info(f"éªŒè¯JSONæ–‡ä»¶: {json_file}")
        
        try:
            # è¯»å–å¹¶è§£æJSONæ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = file_path.stat().st_size
            logger.info(f"  æ–‡ä»¶å¤§å°: {file_size} bytes")
            
            if file_size < 100:  # æ–‡ä»¶å¤ªå°å¯èƒ½ä¸å®Œæ•´
                logger.warning(f"  âš ï¸ æ–‡ä»¶å¯èƒ½ä¸å®Œæ•´ (< 100 bytes)")
            
            # æ£€æŸ¥æ•°æ®ç»“æ„
            if isinstance(data, dict):
                logger.info(f"  âœ… JSONç»“æ„æœ‰æ•ˆï¼ŒåŒ…å« {len(data)} ä¸ªé¡¶çº§é”®")
                
                # æ˜¾ç¤ºä¸»è¦é”®
                main_keys = list(data.keys())[:5]  # æ˜¾ç¤ºå‰5ä¸ªé”®
                logger.info(f"  ä¸»è¦é”®: {main_keys}")
                
                # é€’å½’æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                def check_completeness(obj, path="root", max_depth=3):
                    if max_depth <= 0:
                        return True
                    
                    if isinstance(obj, dict):
                        for key, value in obj.items():
                            if value is None:
                                logger.debug(f"    å‘ç°nullå€¼: {path}.{key}")
                            elif isinstance(value, (dict, list)):
                                check_completeness(value, f"{path}.{key}", max_depth-1)
                    elif isinstance(obj, list):
                        for i, item in enumerate(obj[:3]):  # åªæ£€æŸ¥å‰3ä¸ªå…ƒç´ 
                            check_completeness(item, f"{path}[{i}]", max_depth-1)
                    
                    return True
                
                check_completeness(data)
                
            else:
                logger.error(f"  âŒ JSONæ ¹å¯¹è±¡ä¸æ˜¯å­—å…¸ç±»å‹")
                all_valid = False
            
        except json.JSONDecodeError as e:
            logger.error(f"  âŒ JSONè§£æé”™è¯¯: {e}")
            all_valid = False
        except Exception as e:
            logger.error(f"  âŒ æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
            all_valid = False
    
    return all_valid


def validate_json_content():
    """éªŒè¯JSONå†…å®¹çš„å®Œæ•´æ€§"""
    logger.info("ğŸ” éªŒè¯JSONå†…å®¹å®Œæ•´æ€§")
    
    output_dir = "json_test_output"
    detection_file = Path(output_dir) / "detection_results.json"
    quality_file = Path(output_dir) / "quality_metrics.json"
    
    if not detection_file.exists():
        logger.error("æ£€æµ‹ç»“æœæ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    try:
        # éªŒè¯æ£€æµ‹ç»“æœæ–‡ä»¶
        with open(detection_file, 'r', encoding='utf-8') as f:
            detection_data = json.load(f)
        
        logger.info("æ£€æµ‹ç»“æœæ–‡ä»¶å†…å®¹éªŒè¯:")
        
        # æ£€æŸ¥å¿…éœ€çš„å­—æ®µ
        required_fields = ["metadata", "detection_info", "boundaries", "segments", "summary"]
        for field in required_fields:
            if field in detection_data:
                logger.info(f"  âœ… {field}: å­˜åœ¨")
                
                if field == "boundaries" and isinstance(detection_data[field], list):
                    logger.info(f"    è¾¹ç•Œæ•°é‡: {len(detection_data[field])}")
                elif field == "segments" and isinstance(detection_data[field], list):
                    logger.info(f"    åˆ†æ®µæ•°é‡: {len(detection_data[field])}")
                elif field == "summary" and isinstance(detection_data[field], dict):
                    summary = detection_data[field]
                    logger.info(f"    æ€»æ—¶é•¿: {summary.get('total_duration', 'N/A')}s")
                    logger.info(f"    å¹³å‡åˆ†æ®µæ—¶é•¿: {summary.get('average_segment_duration', 'N/A')}s")
            else:
                logger.error(f"  âŒ {field}: ç¼ºå¤±")
        
        # éªŒè¯è´¨é‡æŒ‡æ ‡æ–‡ä»¶
        if quality_file.exists():
            with open(quality_file, 'r', encoding='utf-8') as f:
                quality_data = json.load(f)
            
            logger.info("è´¨é‡æŒ‡æ ‡æ–‡ä»¶å†…å®¹éªŒè¯:")
            quality_fields = ["detection_metrics", "segment_metrics", "quality_thresholds"]
            for field in quality_fields:
                if field in quality_data:
                    logger.info(f"  âœ… {field}: å­˜åœ¨")
                else:
                    logger.error(f"  âŒ {field}: ç¼ºå¤±")
        
        return True
        
    except Exception as e:
        logger.error(f"éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    setup_logging()
    
    logger.info("ğŸ§ª JSONä¿®å¤åŠŸèƒ½æµ‹è¯•")
    logger.info("=" * 50)
    
    tests = [
        ("JSONåºåˆ—åŒ–åŠŸèƒ½", test_json_serialization),
        ("è§†é¢‘å¤„ç†JSONè¾“å‡º", test_video_processing_json),
        ("JSONå†…å®¹å®Œæ•´æ€§", validate_json_content)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        logger.info(f"\nğŸ”¬ æ‰§è¡Œæµ‹è¯•: {test_name}")
        try:
            result = test_func()
            results.append((test_name, result))
            
            if result:
                logger.info(f"âœ… {test_name}: é€šè¿‡")
            else:
                logger.error(f"âŒ {test_name}: å¤±è´¥")
                
        except Exception as e:
            logger.error(f"âŒ {test_name}: å¼‚å¸¸ - {e}")
            results.append((test_name, False))
    
    # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"  {test_name}: {status}")
    
    logger.info(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ŒJSONä¿®å¤åŠŸèƒ½æ­£å¸¸ï¼")
        return True
    else:
        logger.error("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
