#!/usr/bin/env python3
"""
JSONæ–‡ä»¶éªŒè¯å·¥å…·
éªŒè¯ç”Ÿæˆçš„JSONæ–‡ä»¶çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
"""

import sys
import os
import json
from pathlib import Path
from typing import Dict, Any, List
import argparse

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from loguru import logger


def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logger.remove()
    logger.add(
        sys.stderr,
        level="INFO",
        format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{message}</cyan>"
    )


def validate_detection_results_json(file_path: str) -> bool:
    """éªŒè¯æ£€æµ‹ç»“æœJSONæ–‡ä»¶"""
    logger.info(f"éªŒè¯æ£€æµ‹ç»“æœæ–‡ä»¶: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ£€æŸ¥é¡¶çº§ç»“æ„
        required_keys = ["metadata", "detection_info", "boundaries", "segments", "summary"]
        missing_keys = []
        
        for key in required_keys:
            if key not in data:
                missing_keys.append(key)
        
        if missing_keys:
            logger.error(f"ç¼ºå¤±å¿…éœ€çš„é”®: {missing_keys}")
            return False
        
        # éªŒè¯metadata
        metadata = data["metadata"]
        if not isinstance(metadata, dict):
            logger.error("metadataä¸æ˜¯å­—å…¸ç±»å‹")
            return False
        
        logger.info(f"  ç‰ˆæœ¬: {metadata.get('version', 'N/A')}")
        logger.info(f"  è§†é¢‘è·¯å¾„: {metadata.get('video_path', 'N/A')}")
        
        # éªŒè¯detection_info
        detection_info = data["detection_info"]
        if not isinstance(detection_info, dict):
            logger.error("detection_infoä¸æ˜¯å­—å…¸ç±»å‹")
            return False
        
        logger.info(f"  ç®—æ³•: {detection_info.get('algorithm', 'N/A')}")
        logger.info(f"  å¤„ç†æ—¶é—´: {detection_info.get('processing_time', 'N/A')}s")
        logger.info(f"  å¸§æ•°: {detection_info.get('frame_count', 'N/A')}")
        logger.info(f"  è¾¹ç•Œæ•°: {detection_info.get('boundaries_count', 'N/A')}")
        
        # éªŒè¯ç½®ä¿¡åº¦ç»Ÿè®¡
        if "confidence_stats" in detection_info:
            stats = detection_info["confidence_stats"]
            logger.info(f"  ç½®ä¿¡åº¦èŒƒå›´: {stats.get('min', 'N/A')} - {stats.get('max', 'N/A')}")
            logger.info(f"  å¹³å‡ç½®ä¿¡åº¦: {stats.get('mean', 'N/A')}")
        
        # éªŒè¯boundaries
        boundaries = data["boundaries"]
        if not isinstance(boundaries, list):
            logger.error("boundariesä¸æ˜¯åˆ—è¡¨ç±»å‹")
            return False
        
        logger.info(f"  è¾¹ç•Œåˆ—è¡¨é•¿åº¦: {len(boundaries)}")
        
        # æ£€æŸ¥è¾¹ç•Œæ•°æ®ç»“æ„
        if boundaries:
            boundary_keys = ["frame_number", "timestamp", "confidence", "boundary_type"]
            first_boundary = boundaries[0]
            
            for key in boundary_keys:
                if key not in first_boundary:
                    logger.error(f"è¾¹ç•Œæ•°æ®ç¼ºå¤±é”®: {key}")
                    return False
            
            # éªŒè¯æ•°æ®ç±»å‹
            if not isinstance(first_boundary["frame_number"], int):
                logger.error("frame_numberä¸æ˜¯æ•´æ•°ç±»å‹")
                return False
            
            if not isinstance(first_boundary["timestamp"], (int, float)):
                logger.error("timestampä¸æ˜¯æ•°å€¼ç±»å‹")
                return False
            
            if not isinstance(first_boundary["confidence"], (int, float)):
                logger.error("confidenceä¸æ˜¯æ•°å€¼ç±»å‹")
                return False
        
        # éªŒè¯segments
        segments = data["segments"]
        if not isinstance(segments, list):
            logger.error("segmentsä¸æ˜¯åˆ—è¡¨ç±»å‹")
            return False
        
        logger.info(f"  åˆ†æ®µåˆ—è¡¨é•¿åº¦: {len(segments)}")
        
        # æ£€æŸ¥åˆ†æ®µæ•°æ®ç»“æ„
        if segments:
            segment_keys = ["index", "start_time", "end_time", "duration", "start_frame", "end_frame", "file_path"]
            first_segment = segments[0]
            
            for key in segment_keys:
                if key not in first_segment:
                    logger.error(f"åˆ†æ®µæ•°æ®ç¼ºå¤±é”®: {key}")
                    return False
        
        # éªŒè¯summary
        summary = data["summary"]
        if not isinstance(summary, dict):
            logger.error("summaryä¸æ˜¯å­—å…¸ç±»å‹")
            return False
        
        logger.info(f"  æ€»åˆ†æ®µæ•°: {summary.get('total_segments', 'N/A')}")
        logger.info(f"  æ€»æ—¶é•¿: {summary.get('total_duration', 'N/A')}s")
        logger.info(f"  å¹³å‡åˆ†æ®µæ—¶é•¿: {summary.get('average_segment_duration', 'N/A')}s")
        
        logger.info("âœ… æ£€æµ‹ç»“æœJSONæ–‡ä»¶éªŒè¯é€šè¿‡")
        return True
        
    except json.JSONDecodeError as e:
        logger.error(f"JSONè§£æé”™è¯¯: {e}")
        return False
    except Exception as e:
        logger.error(f"éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return False


def validate_quality_metrics_json(file_path: str) -> bool:
    """éªŒè¯è´¨é‡æŒ‡æ ‡JSONæ–‡ä»¶"""
    logger.info(f"éªŒè¯è´¨é‡æŒ‡æ ‡æ–‡ä»¶: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ£€æŸ¥é¡¶çº§ç»“æ„
        required_keys = ["detection_metrics", "segment_metrics", "quality_thresholds", "quality_assessment"]
        missing_keys = []
        
        for key in required_keys:
            if key not in data:
                missing_keys.append(key)
        
        if missing_keys:
            logger.error(f"ç¼ºå¤±å¿…éœ€çš„é”®: {missing_keys}")
            return False
        
        # éªŒè¯detection_metrics
        detection_metrics = data["detection_metrics"]
        logger.info(f"  æ£€æµ‹ç®—æ³•: {detection_metrics.get('algorithm', 'N/A')}")
        logger.info(f"  å¤„ç†æ—¶é—´: {detection_metrics.get('processing_time', 'N/A')}s")
        logger.info(f"  æ£€æµ‹è¾¹ç•Œæ•°: {detection_metrics.get('boundaries_detected', 'N/A')}")
        logger.info(f"  å¤„ç†é€Ÿåº¦æ¯”: {detection_metrics.get('processing_speed_ratio', 'N/A')}")
        
        # éªŒè¯segment_metrics
        segment_metrics = data["segment_metrics"]
        logger.info(f"  æ€»åˆ†æ®µæ•°: {segment_metrics.get('total_segments', 'N/A')}")
        logger.info(f"  æ€»æ—¶é•¿: {segment_metrics.get('total_duration', 'N/A')}s")
        logger.info(f"  å¹³å‡åˆ†æ®µæ—¶é•¿: {segment_metrics.get('avg_segment_duration', 'N/A')}s")
        
        # éªŒè¯quality_assessment
        quality_assessment = data["quality_assessment"]
        logger.info(f"  æ»¡è¶³æ—¶é•¿è¦æ±‚: {quality_assessment.get('meets_duration_requirements', 'N/A')}")
        logger.info(f"  æ»¡è¶³é€Ÿåº¦è¦æ±‚: {quality_assessment.get('meets_speed_requirements', 'N/A')}")
        
        logger.info("âœ… è´¨é‡æŒ‡æ ‡JSONæ–‡ä»¶éªŒè¯é€šè¿‡")
        return True
        
    except json.JSONDecodeError as e:
        logger.error(f"JSONè§£æé”™è¯¯: {e}")
        return False
    except Exception as e:
        logger.error(f"éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return False


def validate_directory(directory: str) -> bool:
    """éªŒè¯ç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶"""
    logger.info(f"éªŒè¯ç›®å½•: {directory}")
    
    dir_path = Path(directory)
    if not dir_path.exists():
        logger.error(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
        return False
    
    json_files = list(dir_path.glob("*.json"))
    if not json_files:
        logger.warning(f"ç›®å½•ä¸­æ²¡æœ‰JSONæ–‡ä»¶: {directory}")
        return True
    
    logger.info(f"æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
    
    all_valid = True
    
    for json_file in json_files:
        logger.info(f"\néªŒè¯æ–‡ä»¶: {json_file.name}")
        
        # æ ¹æ®æ–‡ä»¶åé€‰æ‹©éªŒè¯æ–¹æ³•
        if "detection_results" in json_file.name:
            valid = validate_detection_results_json(str(json_file))
        elif "quality_metrics" in json_file.name:
            valid = validate_quality_metrics_json(str(json_file))
        else:
            # é€šç”¨JSONéªŒè¯
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    json.load(f)
                logger.info("âœ… JSONæ ¼å¼æœ‰æ•ˆ")
                valid = True
            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSONæ ¼å¼æ— æ•ˆ: {e}")
                valid = False
        
        if not valid:
            all_valid = False
    
    return all_valid


def compare_json_files(file1: str, file2: str) -> bool:
    """æ¯”è¾ƒä¸¤ä¸ªJSONæ–‡ä»¶çš„ç»“æ„"""
    logger.info(f"æ¯”è¾ƒJSONæ–‡ä»¶: {file1} vs {file2}")
    
    try:
        with open(file1, 'r', encoding='utf-8') as f:
            data1 = json.load(f)
        
        with open(file2, 'r', encoding='utf-8') as f:
            data2 = json.load(f)
        
        # æ¯”è¾ƒé¡¶çº§é”®
        keys1 = set(data1.keys())
        keys2 = set(data2.keys())
        
        common_keys = keys1 & keys2
        only_in_1 = keys1 - keys2
        only_in_2 = keys2 - keys1
        
        logger.info(f"  å…±åŒé”®: {len(common_keys)}")
        logger.info(f"  ä»…åœ¨æ–‡ä»¶1ä¸­: {len(only_in_1)}")
        logger.info(f"  ä»…åœ¨æ–‡ä»¶2ä¸­: {len(only_in_2)}")
        
        if only_in_1:
            logger.info(f"  æ–‡ä»¶1ç‹¬æœ‰: {list(only_in_1)}")
        
        if only_in_2:
            logger.info(f"  æ–‡ä»¶2ç‹¬æœ‰: {list(only_in_2)}")
        
        # æ¯”è¾ƒæ•°æ®ç±»å‹
        type_differences = []
        for key in common_keys:
            if type(data1[key]) != type(data2[key]):
                type_differences.append(f"{key}: {type(data1[key])} vs {type(data2[key])}")
        
        if type_differences:
            logger.warning(f"  ç±»å‹å·®å¼‚: {type_differences}")
        
        logger.info("âœ… JSONæ–‡ä»¶æ¯”è¾ƒå®Œæˆ")
        return len(only_in_1) == 0 and len(only_in_2) == 0 and len(type_differences) == 0
        
    except Exception as e:
        logger.error(f"æ¯”è¾ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="JSONæ–‡ä»¶éªŒè¯å·¥å…·")
    parser.add_argument("path", help="è¦éªŒè¯çš„JSONæ–‡ä»¶æˆ–ç›®å½•è·¯å¾„")
    parser.add_argument("--compare", help="æ¯”è¾ƒçš„ç¬¬äºŒä¸ªJSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--type", choices=["detection", "quality", "auto"], 
                       default="auto", help="JSONæ–‡ä»¶ç±»å‹")
    parser.add_argument("--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    setup_logging()
    
    if args.verbose:
        logger.remove()
        logger.add(sys.stderr, level="DEBUG")
    
    logger.info("ğŸ” JSONæ–‡ä»¶éªŒè¯å·¥å…·")
    logger.info("=" * 40)
    
    success = True
    
    if args.compare:
        # æ¯”è¾ƒæ¨¡å¼
        success = compare_json_files(args.path, args.compare)
    elif os.path.isdir(args.path):
        # ç›®å½•éªŒè¯æ¨¡å¼
        success = validate_directory(args.path)
    elif os.path.isfile(args.path):
        # å•æ–‡ä»¶éªŒè¯æ¨¡å¼
        if args.type == "detection" or "detection" in args.path:
            success = validate_detection_results_json(args.path)
        elif args.type == "quality" or "quality" in args.path:
            success = validate_quality_metrics_json(args.path)
        else:
            # è‡ªåŠ¨æ£€æµ‹
            try:
                with open(args.path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if "detection_info" in data:
                    success = validate_detection_results_json(args.path)
                elif "detection_metrics" in data:
                    success = validate_quality_metrics_json(args.path)
                else:
                    logger.info("âœ… JSONæ ¼å¼æœ‰æ•ˆï¼ˆé€šç”¨éªŒè¯ï¼‰")
                    success = True
                    
            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSONæ ¼å¼æ— æ•ˆ: {e}")
                success = False
    else:
        logger.error(f"è·¯å¾„ä¸å­˜åœ¨: {args.path}")
        success = False
    
    if success:
        logger.info("ğŸ‰ éªŒè¯å®Œæˆï¼Œæ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
        sys.exit(0)
    else:
        logger.error("âŒ éªŒè¯å¤±è´¥ï¼Œå‘ç°é—®é¢˜")
        sys.exit(1)


if __name__ == "__main__":
    main()
